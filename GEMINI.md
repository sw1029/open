# AI 수요 예측 모델링 계획

## 1. 데이터 전처리 요약

수요 예측 모델링을 위해 원본 `train.csv`에 대해 다음과 같은 2단계의 데이터 전처리를 수행했습니다.

1.  **데이터 분할**: `영업장명_메뉴명` 컬럼을 기준으로 데이터를 분리하여, 각 영업장 폴더(`data/영업장명/`) 내에 메뉴별 판매량 데이터(`메뉴명.csv`)를 생성했습니다.
2.  **상관계수 분석**: 각 영업장 내에서 메뉴 간의 매출 상관관계를 분석하고, 그 결과를 `data/영업장명.csv` 파일로 저장하여 모델의 피처로 활용할 수 있는 기반을 마련했습니다.

---

## 2. AI 모델 상세 구현 및 결과

### 2.1. XGBoost 기반 모델 구현

시계열 문제를 강력한 피처 엔지니어링을 통해 테이블 형태의 회귀 문제로 변환하여 해결하는 XGBoost 모델을 구현했습니다. 시간 기반으로 검증 데이터를 분리하여 SMAPE 지표로 성능을 측정했습니다.

*   **주요 피처**: 날짜 피처(요일, 주, 월 등), 시차(Lag) 피처, 이동평균(Rolling mean) 피처
*   **검증 SMAPE 점수**: `137.9591`

### 2.2. 상관관계 피처를 이용한 성능 개선

모델의 성능을 향상시키기 위해, 이전에 분석한 메뉴 간 **상관계수** 정보를 활용했습니다.

*   **아이디어**: 특정 메뉴의 판매량을 예측할 때, 해당 메뉴와 가장 상관관계가 높은 다른 메뉴(일명 '최고의 짝꿍')의 과거 판매량을 피처로 사용합니다. 이는 메뉴 간의 상호작용을 모델이 학습하도록 돕습니다.
*   **구현**: '최고의 짝꿍' 메뉴의 1일 전 판매량을 `buddy_lag_1_sales` 라는 새로운 피처로 생성하여 기존 XGBoost 모델의 학습에 추가했습니다.
*   **실행 결과**:
    *   기존 모델 검증 SMAPE 점수: `137.9591`
    *   상관관계 피처 추가 후 SMAPE 점수: **`133.4731`**
*   **결론**: 상관관계 피처를 추가함으로써 모델의 예측 성능이 **유의미하게 개선되었음**을 확인했습니다.

### 2.3. LSTM 모델 구현 및 안정화

PyTorch 기반의 LSTM 모델을 구현했으나, 초기 실행에서 학습 정체 현상과 오류가 발견되어 다음과 같이 안정화 작업을 진행했습니다.

*   **문제점 진단**:
    1.  **학습 정체**: 검증 손실(Validation Loss)이 특정 구간에서 더 이상 감소하지 않고 SMAPE 점수가 개선되지 않음.
    2.  **NameError**: 스크립트 마지막에 `sample_submission_df` 변수를 찾지 못하는 오류 발생.

*   **개선 방안 적용**:
    *   **`NameError` 해결**: 누락되었던 `sample_submission.csv` 파일 로딩 코드를 추가했습니다.
    *   **학습률 스케줄러 (`ReduceLROnPlateau`)**: 검증 손실이 정체될 때 학습률을 동적으로 감소시켜 안정적인 학습을 유도하도록 개선했습니다.
    *   **조기 종료 (Early Stopping)**: 검증 손실이 일정 기간 개선되지 않으면 학습을 중단하고, 가장 성능이 좋았던 시점의 모델 가중치를 저장하여 과적합을 방지하고 효율성을 높였습니다.
    *   **모델 용량 증가**: LSTM의 `hidden_size`를 늘려 모델의 표현력을 높였습니다.

*   **결론**: 상기 개선 사항을 적용한 `train_lstm.py` 스크립트를 최종 완성했으며, 안정적인 학습 및 평가가 가능한 상태입니다.

---

## 3. 종합 및 다음 단계

*   **현재까지의 성과**: XGBoost 모델을 성공적으로 구축하고 피처 엔지니어링을 통해 성능 개선을 확인했으며, LSTM 모델의 구현 및 안정화 작업을 완료했습니다.
*   **향후 방향**:
    1.  **안정화된 LSTM 모델 실행**: 개선된 `train_lstm.py`를 실행하여 XGBoost 모델 대비 성능을 비교 분석합니다.
    2.  **피처 엔지니어링 고도화**: 공휴일, 날씨 등 외부 데이터를 피처로 추가하여 추가적인 성능 향상을 모색합니다.
    3.  **하이퍼파라미터 튜닝**: `Optuna`와 같은 도구를 사용하여 두 모델의 하이퍼파라미터를 최적화합니다.

---

## 4. 추가 개선 계획 및 진행 상황

### 4.1. 학습 과정 모니터링 개선 (완료)

*   **개선 내용**: `train_lstm.py` 스크립트의 학습 진행률을 표시하는 `tqdm` 라이브러리 출력 방식을 개선했습니다.
*   **기존 방식**: 매 에포크가 끝날 때마다 검증 손실(`val_loss`)과 검증 SMAPE(`val_smape`) 점수가 별도의 줄에 출력되어 진행 상황을 한눈에 파악하기 어려웠습니다.
*   **변경 방식**: `tqdm`의 `set_postfix` 기능을 사용하여, 진행률 표시줄 바로 옆에 `val_loss`와 `val_smape`가 실시간으로 표시되도록 수정했습니다. 이를 통해 학습 과정을 훨씬 직관적으로 모니터링할 수 있게 되었습니다.

### 4.2. 조기 종료 조건 최적화 (완료)

*   **개선 내용**: 조기 종료 조건을 기존의 `val_loss`에서 최종 평가지표인 **`val_smape`** 기준으로 변경했습니다.
*   **수정 결과**: 이제 모델은 검증 SMAPE 점수가 더 이상 개선되지 않을 때 학습을 중단하고, 가장 낮은 SMAPE를 기록한 시점의 모델 가중치를 저장합니다. 이를 통해 모델이 최종 목표에 더 직접적으로 최적화되도록 개선했습니다.

### 4.3. 최종 예측 로직 고도화 (완료)

*   **개선 내용**: 임시 코드였던 최종 예측(Step 6) 부분을, 모든 피처(`lag`, `buddy_lag_1_sales`)의 동적 업데이트를 포함하는 **정교한 재귀 예측 로직**으로 완성했습니다.
*   **구현 방식 (일자별 동기화)**:
    1.  **일자별 루프**: 예측이 필요한 날짜를 하루 단위로 순회합니다.
    2.  **당일 예측 완료**: 해당일의 모든 메뉴에 대한 예측을 먼저 완료합니다.
    3.  **미래 피처 업데이트**: 당일의 예측 결과를 사용하여, 다음날 및 그 이후 날짜의 `lag` 피처와 `buddy_lag_1_sales` 피처를 일괄적으로 업데이트합니다.
*   **기대 효과**: 이 일자별 동기화 방식은 메뉴 간의 복잡한 상호 의존성까지 정확하게 처리하여, 신뢰도 높은 최종 예측 결과를 생성합니다.